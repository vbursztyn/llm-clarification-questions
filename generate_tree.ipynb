{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJVQykEbM6Lx",
        "outputId": "87cc1900-37eb-4dda-af0e-fb1dff525c1d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive/Clarifying_Questions_GPT_Research'"
      ],
      "metadata": {
        "id": "cdAOWc8D9OgD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd {drive_dir} && pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "DSgUZkb29QnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "mXXrK9DqGwRJ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "import pickle\n",
        "\n",
        "import random\n",
        "\n",
        "import copy\n",
        "\n",
        "import sys\n",
        "\n",
        "import os\n",
        "\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(drive_dir+\"/openai_key.key\", \"r\") as f:\n",
        "    openai.api_key = f.read()"
      ],
      "metadata": {
        "id": "jK4Pvc8i9dmL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generates text using gpt-3.5 given a conversation context\n",
        "def generateText(context):\n",
        "  assert isinstance(context, list), f\"input is not a context list, got {type(context)}\"\n",
        "  resp = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=context)\n",
        "\n",
        "  return resp['choices'][0]['message'][\"content\"]\n",
        "\n",
        "# appends a new entry to a conversation context\n",
        "def appendContext(text, context, role):\n",
        "  assert role == \"user\" or role == \"assistant\", f\"unexpected role, got: {role}\"\n",
        "\n",
        "  if role == \"user\":\n",
        "    assert context[-1][\"role\"] == \"assistant\", f\"incompatible adjecent role, got user\"\n",
        "    context.append({\"role\": \"user\", \"content\": text})\n",
        "  else:\n",
        "    assert context[-1][\"role\"] == \"user\", f\"incompatible adjecent role, got assistant\"\n",
        "    context.append({\"role\": \"assistant\", \"content\": text})\n",
        "\n",
        "  return\n",
        "\n",
        "# generates a new question/suggestion given a conversation context\n",
        "def generateQ(context):\n",
        "  role = context[-1][\"role\"]\n",
        "  assert role == \"user\", f\"unexpected role, got: {role}\"\n",
        "\n",
        "  return generateText(context)"
      ],
      "metadata": {
        "id": "c-9rhM-0t8SM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt used to extract the possible responses to a question\n",
        "def getOptionsPrompt(q):\n",
        "  return f\"Here is a question:\\n{q}\\n\\nTask:\\nThe person asking the question presents several options to an assistant. What are the options? List the options using only the words in the question itself.\"\n",
        "\n",
        "# given a string that has a python list, extracts and returns said python list\n",
        "def str2lst(l):\n",
        "  assert '[' in l, f\"string does not seem to contain a list, string: {l}\"\n",
        "  assert ']' in l, f\"string does not seem to contain a list, string: {l}\"\n",
        "\n",
        "  l = l.split(\"[\",1)[1]\n",
        "  l = l.split(\"]\",1)[0]\n",
        "\n",
        "  if '\"' in l:\n",
        "    l = l.replace('\"', '')\n",
        "  elif \"'\" in l:\n",
        "    l = l.replace(\"'\", '')\n",
        "  else:\n",
        "    assert 1 == 0, f\"string does not seem to contain a list, string: {l}\"\n",
        "\n",
        "  l = l.replace(\", \", ',')\n",
        "  l = l.replace(\"  \", ' ')\n",
        "\n",
        "  return l.split(\",\")\n",
        "\n",
        "# extracts the possible responses from a given question and returns them in a python list\n",
        "def getOptions(q):\n",
        "  context = [{\"role\": \"user\", \"content\":getOptionsPrompt(q)}]\n",
        "\n",
        "  text_options = generateText(context)\n",
        "  appendContext(text_options, context, \"assistant\")\n",
        "\n",
        "  appendContext(\"Return options as a python list:\", context, \"user\")\n",
        "\n",
        "  return str2lst(generateText(context))"
      ],
      "metadata": {
        "id": "eR_3iBAJt_fQ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isSuggestion(gen):\n",
        "    return not '?' in gen and (not ' or ' in gen or '!' in gen) # this still needs a lot of work, but as a mvp it's fine\n",
        "\n",
        "def isQuestion(gen):\n",
        "    return ' or ' in gen and '?' in gen # this works surprisingly well, however might need to get more sophisticated"
      ],
      "metadata": {
        "id": "o5zIOa7aHJ8F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates new node; creates edge from parent to new node; returns new node\n",
        "def expandTree(parent, ans_num, new_id, g_attempts=3):\n",
        "\n",
        "    # creating node, where None fields will chage depending on what is generated\n",
        "    node = {\n",
        "        'id':  new_id, # parent['id'] + ans_num + 1, # index of this node in the tree array\n",
        "\n",
        "        'parent_id': parent['id'], # index of the parent node in the tree array\n",
        "\n",
        "        'idx_in_parent': ans_num, # index that represents the edge from parent that goes to this node\n",
        "\n",
        "        'layer_num': parent['layer_num'] + 1, # depth of this node in the tree\n",
        "\n",
        "        'flag': None, # flag indicating wether this node contains a question, suggestion, or error\n",
        "\n",
        "        'generated_text': None, # text that was generated\n",
        "\n",
        "        'full_context': None, # context (i.e. the history of questions and answers) that lead to this node\n",
        "\n",
        "        'childrens_option': None, # possible answers (edges) for this node\n",
        "\n",
        "        'childrens_done_bool': None, # wether the answers (edges) have been used to generate child nodes\n",
        "\n",
        "        'childrens_id': None, # the indexes of the children nodes in the tree array\n",
        "    }\n",
        "\n",
        "    # creating edge from parent to node\n",
        "    parent['childrens_done_bool'][ans_num] = True\n",
        "    parent['childrens_id'][ans_num] = node['id']\n",
        "\n",
        "    # adding edge, i.e. the user's chosen option, to context\n",
        "    new_context = copy.copy(parent['full_context']) # can create shallow copy because pickle can handle references\n",
        "    appendContext(parent['childrens_option'][ans_num], new_context, 'user')\n",
        "\n",
        "    # try to generate a valid question, if succesfull break from loop\n",
        "    for i in range(g_attempts):\n",
        "\n",
        "        # IN PREVIOUS CODE, GENERATEQ RECEIVED CONTEXT AND CHOSEN OPTION,\n",
        "        #generation = generateQ(parent['full_context'], parent['childrens_option'][ans_num])\n",
        "        generation = generateQ(new_context)\n",
        "\n",
        "        if isSuggestion(generation):\n",
        "          node['flag'] = 's'\n",
        "          break\n",
        "\n",
        "        if isQuestion(generation):\n",
        "          node['flag'] = 'q'\n",
        "          break\n",
        "\n",
        "    node['generated_text'] = generation\n",
        "    # PREVIOUS CODE\n",
        "    #node['full_context'] = f\"{parent['full_context']}\\nUser:{parent['childrens_option'][ans_num]}\\nChatGPT:{generation}\"\n",
        "    appendContext(generation, new_context, 'assistant')\n",
        "    node['full_context'] = new_context\n",
        "\n",
        "    if node['flag'] != 's' and node['flag'] != 'q':\n",
        "        node['flag'] = 'e'\n",
        "\n",
        "    else:\n",
        "        #node['flag'] = 'q'\n",
        "        node['childrens_option'] = getOptions(generation)\n",
        "        node['childrens_done_bool'] = [False for x in range(len(node['childrens_option']))]\n",
        "        node['childrens_id'] = [None for x in range(len(node['childrens_option']))]\n",
        "\n",
        "    return node"
      ],
      "metadata": {
        "id": "igZrm725HMbP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_seed = \"Ask me one either or question at a time to help me find out where I want to go travel\""
      ],
      "metadata": {
        "id": "WqDS-luw6fGl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFirstNode(seed, options_prompt, g_attempts):\n",
        "\n",
        "    # if seed is None, set seed to a default\n",
        "    if not seed:\n",
        "        seed = default_seed\n",
        "\n",
        "    # starting context that contains only the seed as an user input\n",
        "    starting_context = [{\"role\": \"user\", \"content\": seed}]\n",
        "\n",
        "    # try multiple times to generate a valid question, if succesfull break from loop\n",
        "    flag = 'e' # flag for wether the generated text is a valid question\n",
        "    for i in range(g_attempts):\n",
        "\n",
        "      # generating the first question GPT makes given the seed\n",
        "      first_q = generateQ(starting_context)\n",
        "\n",
        "      if isSuggestion(first_q):\n",
        "        flag = 's'\n",
        "        break\n",
        "\n",
        "      if isQuestion(first_q):\n",
        "        flag = 'q'\n",
        "        break\n",
        "\n",
        "    # if the generated question is not valid after g_attempts tried, throw an error\n",
        "    assert flag != 'e', f\"first question was not valid, question: {first_q}\"\n",
        "\n",
        "    # appending first question to the context as the assistant response\n",
        "    appendContext(first_q, starting_context, \"assistant\")\n",
        "\n",
        "    # getting the options from the first question\n",
        "    options = getOptions(first_q)\n",
        "\n",
        "    node = {\n",
        "        'id': 0,\n",
        "\n",
        "        'parent_id': None,\n",
        "\n",
        "        'idx_in_parent': None,\n",
        "\n",
        "        'layer_num': 0,\n",
        "\n",
        "        'flag': 'q',\n",
        "\n",
        "        'generated_text': first_q,\n",
        "\n",
        "        'full_context': starting_context,\n",
        "\n",
        "        'childrens_option': options,\n",
        "\n",
        "        'childrens_done_bool': [False for x in range(len(options))],\n",
        "\n",
        "        'childrens_id': [None for x in range(len(options))]\n",
        "    }\n",
        "\n",
        "    return node"
      ],
      "metadata": {
        "id": "fQ8T0esWHRCo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nextInDPS(tree_dic):\n",
        "    # get id of the next node according to dps\n",
        "    r = tree_dic['dps_cor'][0]\n",
        "    c = tree_dic['dps_cor'][1]\n",
        "    node_id = tree_dic['ids_by_layer'][r][c]\n",
        "\n",
        "    # if this node is unfinished, return node id\n",
        "    if node_id in tree_dic['unfinished_ids']:\n",
        "        return node_id\n",
        "\n",
        "    # else, pass to this function the next node of the same depth d, or if all nodes in d done, the first node of d + 1\n",
        "    else:\n",
        "\n",
        "        if len(tree_dic['ids_by_layer'][r]) - 1 > c:\n",
        "            tree_dic['dps_cor'] = [r, c+1]\n",
        "        elif len(tree_dic['ids_by_layer']) - 1 > r:\n",
        "            tree_dic['dps_cor'] = [r+1, 0]\n",
        "        else: return None\n",
        "\n",
        "\n",
        "    return nextInDPS(tree_dic)"
      ],
      "metadata": {
        "id": "q_XNWaKlHTIl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path to pickle that stores tree to load. If there's no path or the pickle is not found, start generating the tree from scratch\n",
        "pkl_path = '/content/drive/MyDrive/Clarifying_Questions_GPT_Research/Trees'"
      ],
      "metadata": {
        "id": "VUgRNgK4la2y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepDic4Save(tree_dic):\n",
        "  # turn tree_dic pickle serializable by converting the sets to lists\n",
        "  tree_dic['unfinished_ids'] = list(tree_dic['unfinished_ids'])\n",
        "  tree_dic['suggestion_ids'] = list(tree_dic['suggestion_ids'])\n",
        "  tree_dic['error_ids'] = list(tree_dic['error_ids'])\n",
        "  return\n",
        "\n",
        "def prepDic4Use(tree_dic):\n",
        "  # turn lists into sets where we need a set instead of a list\n",
        "  tree_dic['unfinished_ids'] = set(tree_dic['unfinished_ids'])\n",
        "  tree_dic['suggestion_ids'] = set(tree_dic['suggestion_ids'])\n",
        "  tree_dic['error_ids'] = set(tree_dic['error_ids'])\n",
        "  return\n",
        "\n",
        "def loadTreePkl(filename):\n",
        "    # Opening pickle file\n",
        "    with open(os.path.join(pkl_path, filename), 'rb') as f:\n",
        "        # Reading from pickle file\n",
        "        tree_dic = pickle.load(f)\n",
        "    # turn lists into sets where we need a set instead of a list\n",
        "    prepDic4Use(tree_dic)\n",
        "    print('Tree Loaded')\n",
        "\n",
        "    return tree_dic\n",
        "\n",
        "def saveTreePkl(tree_dic, filename):\n",
        "    # turn tree_dic pickle serializable\n",
        "    prepDic4Save(tree_dic)\n",
        "\n",
        "     # save tree to a pickle file\n",
        "    if pkl_path:\n",
        "        with open(os.path.join(pkl_path, filename), \"wb\") as f:\n",
        "            pickle.dump(tree_dic, f)\n",
        "        print('Tree Saved')\n",
        "\n",
        "    # turn lists into sets where we need a set instead of a list\n",
        "    prepDic4Use(tree_dic)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "Aql__dnkHXHh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tree(prompts, gen_num=10, gen_attempts=3, filename=None, tick=None):\n",
        "\n",
        "    if not tick: tick = gen_num\n",
        "\n",
        "    try:\n",
        "        tree_dic = loadTreePkl(filename)\n",
        "\n",
        "    except:\n",
        "        print('Starting New Tree')\n",
        "        first_node = getFirstNode(prompts['seed'],\n",
        "                                    prompts['extract_options'] if prompts['extract_options'] else \"default 'extract_options' prompt\", # I have not implemented this yet\n",
        "                                    gen_attempts)\n",
        "\n",
        "        tree_dic = {\n",
        "        'tree': [first_node],\n",
        "\n",
        "        'prompts': prompts,\n",
        "\n",
        "        'current_node': 0,\n",
        "\n",
        "        'dps_cor': [0,0],\n",
        "\n",
        "        'unfinished_ids': {0},\n",
        "\n",
        "        'ids_by_layer': [[0]],\n",
        "\n",
        "        'suggestion_ids': set(),\n",
        "\n",
        "        'error_ids': set()\n",
        "        }\n",
        "\n",
        "    for it in range(gen_num):\n",
        "        print(it)\n",
        "\n",
        "        # if the current node is None, that means the tree is completed, so exit out of the loop\n",
        "        if tree_dic['current_node'] == None: break\n",
        "\n",
        "        # get current node\n",
        "        node = tree_dic['tree'][tree_dic['current_node']]\n",
        "\n",
        "        # get edge options\n",
        "        options = [idx for idx in range(len(node['childrens_option'])) if not node['childrens_done_bool'][idx]]\n",
        "\n",
        "        # manage unfinished set\n",
        "        if len(options) == 1:\n",
        "            tree_dic['unfinished_ids'].remove(node['id'])\n",
        "        else:\n",
        "            tree_dic['unfinished_ids'].add(node['id'])\n",
        "\n",
        "        # expand the tree\n",
        "        node = expandTree(node, random.sample(options, k=1)[0], len(tree_dic['tree']), g_attempts)\n",
        "\n",
        "        # add node to tree\n",
        "        assert node['id'] == len(tree_dic['tree'])\n",
        "        tree_dic['tree'].append(node)\n",
        "\n",
        "        # add to ids_by_layers; append to end of list if this is the first node in this depth\n",
        "        if len(tree_dic['ids_by_layer']) > node['layer_num']:\n",
        "            tree_dic['ids_by_layer'][node['layer_num']].append(node['id'])\n",
        "        else:\n",
        "            tree_dic['ids_by_layer'].append([node['id']])\n",
        "\n",
        "        # add to suggestion or error if required, sample next node from unfinished node list\n",
        "        if node['flag'] == 's':\n",
        "            tree_dic['suggestion_ids'].add(node['id'])\n",
        "            tree_dic['current_node'] = nextInDPS(tree_dic)\n",
        "\n",
        "        elif node['flag'] == 'e':\n",
        "            tree_dic['error_ids'].add(node['id'])\n",
        "            tree_dic['current_node'] = nextInDPS(tree_dic)\n",
        "\n",
        "        else:\n",
        "            tree_dic['current_node'] = node['id']\n",
        "\n",
        "        # save to pickle\n",
        "        if filename and ((it+1) % tick) == 0:\n",
        "            saveTreePkl(tree_dic, filename)\n",
        "\n",
        "    # last save into pickle\n",
        "    saveTreePkl(tree_dic, filename)\n",
        "\n",
        "    print('Done')\n",
        "    return tree_dic"
      ],
      "metadata": {
        "id": "168PdOgkHeo2"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_attempts = 3\n",
        "\n",
        "node_gen_num = 100 # number of nodes that should be generated before stopping / could be None, setting the stopping time to the default of the next completed branch\n",
        "save_tick = None # number of nodes until new pickle is saved\n",
        "\n",
        "fname = 'GPT_test_tree.pkl'\n",
        "# this is a dictionary of prompts used in the tree generation process. If the value is None, a default option is used instead\n",
        "prompts = {\n",
        "    'seed': \"Ask me one either or question at a time to help me find out where I want to go travel. Ask me many questions before giving me a suggestion\", # the seed prompt that elicits the behaviour of asking clarifying questions from the LLM; default behaviour is a prompt inside the generate_tree function\n",
        "    'extract_options': None, # the prompt to extract the possible answers to a given question; default behaviour is a prompt inside the generate_tree function\n",
        "    # Not implemented yet\n",
        "    'is_suggestion': None, # the prompt used to deetermine wether the LLM generated a suggestion; default behaviour is to see if the string contains \"?\"\n",
        "    'is_question': None # the prompt used to deetermine wether the LLM generated a question with options; default behaviour is to see if the string contains \" or \"\n",
        "}"
      ],
      "metadata": {
        "id": "NzlD7X0kHjUl"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = generate_tree(prompts, gen_num=79, gen_attempts=3, filename=fname, tick=10)"
      ],
      "metadata": {
        "id": "x3Ee_zJ5Ho7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = loadTreePkl(fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfsGyoGv91a",
        "outputId": "824dfa28-664e-4169-86e8-dc9040f2b7d2"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(f\"# of nodes: {len(tree['tree'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esUkQq7-0ADB",
        "outputId": "da348236-65b1-4ac1-dd97-e613e979269c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'# of nodes: 300'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(f\"max depth of tree: {len(tree['ids_by_layer'])}\")\n",
        "# pprint.pprint(tree['ids_by_layer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3I7qYUcHuK0",
        "outputId": "988046f9-f6f3-4ff4-f8fb-f5652a277017"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'max depth of tree: 11'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(f\"# of unfinished nodes: {len(tree['unfinished_ids'])}\")\n",
        "pprint.pprint(f\"# of completly explored nodes: {len(tree['tree']) - len(tree['unfinished_ids'])}\")\n",
        "# pprint.pprint(tree['unfinished_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVngRdsmJcZ9",
        "outputId": "2d968db3-6697-4457-dc03-03a628108012"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'# of unfinished nodes: 163'\n",
            "'# of completly explored nodes: 137'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(f\"# of completed chats: {len(tree['suggestion_ids'])}\")\n",
        "# pprint.pprint(tree['suggestion_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wwUtGJaJe0r",
        "outputId": "868b7e9c-9787-4d03-e3f6-a461789223db"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'# of completed chats: 82'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(f\"# of error nodes: {len(tree['error_ids'])}\")\n",
        "pprint.pprint(tree['error_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnfaUHODJgbg",
        "outputId": "86d16cba-7bba-42c4-c177-b1b3bf531cba"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'# of error nodes: 1'\n",
            "{163}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_id = random.sample([i for i in range(len(tree['tree']))], k=1)[0]\n",
        "\n",
        "node_id = random.sample(tree['suggestion_ids'], k=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXOj3yUk0p2O",
        "outputId": "9b1c2951-fea6-4aaa-8960-d1a172d0a111"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-167-7e89bc2a67f5>:3: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  node_id = random.sample(tree['suggestion_ids'], k=1)[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(tree['tree'][node_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtd0quM0GelK",
        "outputId": "70caf79e-2c61-4d12-85d3-b837e7f0390d"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'childrens_done_bool': [False],\n",
            " 'childrens_id': [None],\n",
            " 'childrens_option': ['Alps within your home country'],\n",
            " 'flag': 's',\n",
            " 'full_context': [{'content': 'Ask me one either or question at a time to help '\n",
            "                              'me find out where I want to go travel. Ask me '\n",
            "                              'many questions before giving me a suggestion',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Sure! Here's the first question: Do you prefer \"\n",
            "                              'beach vacations or mountain getaways?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'mountain getaways', 'role': 'user'},\n",
            "                  {'content': \"Great! Here's the next question: Are you more \"\n",
            "                              'interested in hiking and outdoor activities or '\n",
            "                              'exploring quaint towns and cultural sights?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'Exploring quaint towns and cultural sights',\n",
            "                   'role': 'user'},\n",
            "                  {'content': 'Got it! Next question: Do you prefer a colder '\n",
            "                              'climate with snow-capped mountains or a warmer '\n",
            "                              'climate with lush greenery and scenic views?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'colder climate with snow-capped mountains',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Interesting choice! Here's the next question: \"\n",
            "                              'Are you drawn to destinations with rich '\n",
            "                              'historical and architectural landmarks, or do '\n",
            "                              'you prefer locations with a strong connection '\n",
            "                              'to nature and wildlife?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'locations with a strong connection to nature '\n",
            "                              'and wildlife',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Sounds like a nature enthusiast! Here's the \"\n",
            "                              'next question: Do you prefer destinations with '\n",
            "                              'well-developed hiking trails and national '\n",
            "                              'parks, or are you open to more '\n",
            "                              'off-the-beaten-path locations for a unique and '\n",
            "                              'adventurous experience?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'well-developed hiking trails and national parks',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Excellent! Here's the next question: Would you \"\n",
            "                              'rather travel to a popular and well-known '\n",
            "                              'mountain destination, or are you interested in '\n",
            "                              'discovering hidden gems and lesser-known spots '\n",
            "                              'that offer equally spectacular mountain '\n",
            "                              'scenery?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'Travel to a popular and well-known mountain '\n",
            "                              'destination',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Got it! Here's the next question: Are you \"\n",
            "                              'interested in experiencing a vibrant nightlife '\n",
            "                              'scene in addition to the natural beauty of the '\n",
            "                              'mountains, or do you prefer a more serene and '\n",
            "                              'tranquil atmosphere?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'Experiencing the natural beauty of the '\n",
            "                              'mountains',\n",
            "                   'role': 'user'},\n",
            "                  {'content': \"Understood! Here's the next question: Are you \"\n",
            "                              'open to international travel or are you looking '\n",
            "                              'for a destination within your home country?',\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'Looking for a destination within your home '\n",
            "                              'country',\n",
            "                   'role': 'user'},\n",
            "                  {'content': 'Alright! Final question: Which of the following '\n",
            "                              'regions in your country are you most interested '\n",
            "                              'in exploring: the Rockies, the Appalachians, '\n",
            "                              'the Sierra Nevada, the Cascades, or the Alps '\n",
            "                              \"(if you're outside of the U.S.)?\",\n",
            "                   'role': 'assistant'},\n",
            "                  {'content': 'the Alps', 'role': 'user'},\n",
            "                  {'content': 'Based on your preferences for mountain '\n",
            "                              'getaways, exploring quaint towns and cultural '\n",
            "                              'sights, a colder climate with snow-capped '\n",
            "                              'mountains, a strong connection to nature and '\n",
            "                              'wildlife, well-developed hiking trails and '\n",
            "                              'national parks, and a popular and well-known '\n",
            "                              'mountain destination, I suggest you consider '\n",
            "                              'visiting the Alps within your home country. The '\n",
            "                              'Alps offer stunning natural beauty, charming '\n",
            "                              'alpine villages, and numerous outdoor '\n",
            "                              'activities such as hiking, skiing, and '\n",
            "                              'mountaineering. You can also immerse yourself '\n",
            "                              'in the rich local culture and indulge in '\n",
            "                              'delicious alpine cuisine. Enjoy your trip to '\n",
            "                              'the majestic Alps!',\n",
            "                   'role': 'assistant'}],\n",
            " 'generated_text': 'Based on your preferences for mountain getaways, exploring '\n",
            "                   'quaint towns and cultural sights, a colder climate with '\n",
            "                   'snow-capped mountains, a strong connection to nature and '\n",
            "                   'wildlife, well-developed hiking trails and national parks, '\n",
            "                   'and a popular and well-known mountain destination, I '\n",
            "                   'suggest you consider visiting the Alps within your home '\n",
            "                   'country. The Alps offer stunning natural beauty, charming '\n",
            "                   'alpine villages, and numerous outdoor activities such as '\n",
            "                   'hiking, skiing, and mountaineering. You can also immerse '\n",
            "                   'yourself in the rich local culture and indulge in '\n",
            "                   'delicious alpine cuisine. Enjoy your trip to the majestic '\n",
            "                   'Alps!',\n",
            " 'id': 263,\n",
            " 'idx_in_parent': 4,\n",
            " 'layer_num': 9,\n",
            " 'parent_id': 262}\n"
          ]
        }
      ]
    }
  ]
}